{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQ2F+v58HDHE76L90b9ijR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IamAgranshRastogi/Neural_Network/blob/main/Implement_CNN_text_classifctn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-aUYG8pArmT"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers import Embedding\n",
        "from keras.preprocessing import sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Our dictionary will contain only of the top 7000 words appearing most frequently\n",
        "top_words = 7000\n",
        "# Now we split our data-set into training and test data\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYbZnIQvAzwG",
        "outputId": "93b56c56-1b61-497a-9e8e-ca862362e53a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at the nature of training data\n",
        "print(X_train[0])\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPqUp6e1A7hu",
        "outputId": "4b8f992b-0057-47cc-924f-424e65a8d740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of training data: ')\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSiMdyUoBDCk",
        "outputId": "530be3d5-4196-42d4-fe5c-c33c56157131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training data: \n",
            "(25000,)\n",
            "(25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of test data: ')\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIy_S8w-BIl0",
        "outputId": "0ea2abf5-3688-4ed0-921b-f91d6c5049cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of test data: \n",
            "(25000,)\n",
            "(25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding the data samples to a maximum review length in words\n",
        "import keras\n",
        "max_words = 450\n",
        "X_train = keras.utils.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = keras.utils.pad_sequences(X_test, maxlen=max_words)"
      ],
      "metadata": {
        "id": "jnHoyrjWBKVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the CNN Model\n",
        "model = Sequential()      # initilaizing the Sequential nature for CNN model"
      ],
      "metadata": {
        "id": "z0NhlL_8BVUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the embedding layer which will take in maximum of 450 words as input and provide a 32 dimensional output of those words which belong in the top_words dictionary\n",
        "model.add(Embedding(top_words, 32, input_length=max_words))\n",
        "model.add(Conv1D(32, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbzMxYgABYmU",
        "outputId": "515a82a4-def4-409a-e19d-18bfd791c2bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 450, 32)           224000    \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 450, 32)           3104      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 225, 32)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 7200)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 250)               1800250   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 251       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,027,605\n",
            "Trainable params: 2,027,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the data onto model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-jB0cc_Bc8Z",
        "outputId": "a3886277-6fcb-495f-c42a-e65af2ca24cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "196/196 - 36s - loss: 0.5268 - accuracy: 0.6964 - val_loss: 0.3367 - val_accuracy: 0.8565 - 36s/epoch - 183ms/step\n",
            "Epoch 2/2\n",
            "196/196 - 37s - loss: 0.2250 - accuracy: 0.9138 - val_loss: 0.2659 - val_accuracy: 0.8891 - 37s/epoch - 188ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa573d92650>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting score metrics from our model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)"
      ],
      "metadata": {
        "id": "qOcCSmxOBhlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displays the accuracy of correct sentiment prediction over test data\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReerkRVSBlBe",
        "outputId": "99df73f3-348f-46f8-ae90-dc8f49edb1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 88.91%\n"
          ]
        }
      ]
    }
  ]
}